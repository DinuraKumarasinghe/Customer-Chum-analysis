{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction Analysis\n",
    "\n",
    "This notebook analyzes customer churn data and builds predictive models to identify customers likely to churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import missingno as msno\n",
    "import pickle\n",
    "# %matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First 5 rows:\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last few rows\n",
    "print(\"Last 5 rows:\")\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"Dataset Info:\")\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='Exited', data=dataset)\n",
    "plt.title('Distribution of Churn (Exited)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "dataset = dataset.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "print(\"Dataset after removing unnecessary columns:\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze unique values in each column\n",
    "for column in dataset.columns:\n",
    "    unique_values = np.unique(dataset[column].fillna('0'))\n",
    "    nr_values = len(unique_values)\n",
    "    if nr_values <= 12:\n",
    "        print(f'Number of values in {column}: {nr_values} -> {unique_values}')\n",
    "    else:\n",
    "        print(f'Number of values in {column}: {nr_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot categorical features against churn\n",
    "categorical_features = ['Geography', 'Tenure', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'Age']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x=feature, data=dataset, hue='Exited')\n",
    "    plt.title(f'Churn Distribution by {feature}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for numerical variables\n",
    "numerical_vars = ['CreditScore', 'EstimatedSalary', 'Balance']\n",
    "\n",
    "for var in numerical_vars:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x=dataset[var])\n",
    "    plt.title(f'Box Plot of {var} (Outlier Detection)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode Gender\n",
    "le = LabelEncoder()\n",
    "dataset['Gender'] = le.fit_transform(dataset['Gender'])\n",
    "print(\"Gender encoding: 0 = Female, 1 = Male\")\n",
    "print(dataset[['Gender']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode Geography\n",
    "dataset_encoded = pd.get_dummies(dataset, columns=['Geography'], drop_first=True)\n",
    "print(\"Dataset after one-hot encoding:\")\n",
    "dataset_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data first to avoid data leakage\n",
    "X = dataset_encoded.drop('Exited', axis=1)\n",
    "y = dataset_encoded['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-squared feature selection\n",
    "X_train_abs = X_train.abs()\n",
    "\n",
    "sf = SelectKBest(score_func=chi2, k='all')\n",
    "sf_fit = sf.fit(X_train_abs, y_train)\n",
    "\n",
    "# Create dataframe with feature scores\n",
    "feature_scores_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'scores': sf_fit.scores_\n",
    "})\n",
    "\n",
    "# Sort by score descending and take top 20\n",
    "feature_scores_df = feature_scores_df.sort_values(by='scores', ascending=False).head(20)\n",
    "\n",
    "# Plot feature scores\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='scores', y='feature', data=feature_scores_df, color='blue')\n",
    "sns.set_style('whitegrid')\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.xlabel('Chi-squared Score', fontsize=14)\n",
    "plt.title('Top 20 Features by Chi-Squared Score', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest feature importance\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "indices = np.argsort(rf.feature_importances_)[::-1]\n",
    "\n",
    "print(\"Feature Importance Ranking:\")\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, X_train.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features using Random Forest\n",
    "sfm = SelectFromModel(rf, threshold='median', prefit=True)\n",
    "print('Number of features before selection: {}'.format(X_train.shape[1]))\n",
    "n_features = sfm.transform(X_train).shape[1]\n",
    "print('Number of features after selection: {}'.format(n_features))\n",
    "selected_vars = list(X_train.columns[sfm.get_support()])\n",
    "print(\"Selected features:\", selected_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Feature-Engineered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataset with selected features\n",
    "datasetFe = dataset_encoded[selected_vars + ['Exited']]\n",
    "print(\"Feature-engineered dataset:\")\n",
    "datasetFe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze unique values in selected features\n",
    "print(\"\\nUnique values in selected features:\")\n",
    "for column in datasetFe.columns:\n",
    "    unique_values = np.unique(datasetFe[column].fillna('0'))\n",
    "    nr_values = len(unique_values)\n",
    "    if nr_values <= 12:\n",
    "        print(f'{column}: {nr_values} values -> {unique_values}')\n",
    "    else:\n",
    "        print(f'{column}: {nr_values} values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Handle Class Imbalance with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update X and y with selected features\n",
    "X = datasetFe.drop('Exited', axis=1)\n",
    "y = datasetFe['Exited']\n",
    "\n",
    "# Split again with selected features\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_bal).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create balanced DataFrame for visualization\n",
    "balanced_df = pd.DataFrame(X_train_bal, columns=X_train.columns)\n",
    "balanced_df['Exited'] = y_train_bal\n",
    "\n",
    "# Plot categorical features after balancing\n",
    "categorical_features = [col for col in ['Tenure', 'IsActiveMember'] if col in balanced_df.columns]\n",
    "\n",
    "for feature in categorical_features:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(x=feature, data=balanced_df, hue='Exited')\n",
    "    plt.title(f\"Class Distribution by {feature} (After SMOTE)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot numerical features after balancing\n",
    "numerical_features = [col for col in ['Age', 'CreditScore', 'Balance', 'EstimatedSalary'] if col in balanced_df.columns]\n",
    "\n",
    "for feature in numerical_features:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.kdeplot(data=balanced_df, x=feature, hue='Exited', fill=True, common_norm=False)\n",
    "    plt.title(f\"Distribution of {feature} by Class (After SMOTE)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train_bal, y_train_bal)\n",
    "y_pred_rf = model_rf.predict(X_test_sc)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf, normalize='true')\n",
    "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=model_rf.classes_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp_rf.plot(cmap='Blues', values_format=\".2f\")\n",
    "plt.title(\"Random Forest - Confusion Matrix (Percentages)\")\n",
    "plt.show()\n",
    "\n",
    "# Metrics\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_rf):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=[\"No Churn\", \"Churn\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model_lr = LogisticRegression(max_iter=5000, random_state=42)\n",
    "model_lr.fit(X_train_bal, y_train_bal)\n",
    "y_pred_lr = model_lr.predict(X_test_sc)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr, normalize='true')\n",
    "disp_lr = ConfusionMatrixDisplay(confusion_matrix=cm_lr, display_labels=model_lr.classes_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp_lr.plot(cmap='Blues', values_format=\".2f\")\n",
    "plt.title(\"Logistic Regression - Confusion Matrix (Percentages)\")\n",
    "plt.show()\n",
    "\n",
    "# Metrics\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_lr):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=[\"No Churn\", \"Churn\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_xgb = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb.fit(X_train_bal, y_train_bal)\n",
    "y_pred_xgb = model_xgb.predict(X_test_sc)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_xgb = confusion_matrix(y_test, y_pred_xgb, normalize=\"true\")\n",
    "disp_xgb = ConfusionMatrixDisplay(confusion_matrix=cm_xgb, display_labels=model_xgb.classes_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp_xgb.plot(cmap=\"Blues\")\n",
    "plt.title(\"XGBoost - Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Metrics\n",
    "print(\"XGBoost Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=[\"No Churn\", \"Churn\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "models = ['Random Forest', 'Logistic Regression', 'XGBoost']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_rf),\n",
    "    accuracy_score(y_test, y_pred_lr),\n",
    "    accuracy_score(y_test, y_pred_xgb)\n",
    "]\n",
    "roc_aucs = [\n",
    "    roc_auc_score(y_test, y_pred_rf),\n",
    "    roc_auc_score(y_test, y_pred_lr),\n",
    "    roc_auc_score(y_test, y_pred_xgb)\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'ROC AUC': roc_aucs\n",
    "})\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='Model', y='Accuracy', data=comparison_df)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='Model', y='ROC AUC', data=comparison_df)\n",
    "plt.title('Model ROC AUC Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best model (based on your evaluation)\n",
    "best_model = model_rf  # Change this to your preferred model\n",
    "\n",
    "# Adding predictions back to the original dataset\n",
    "dataset_encoded['Exited Prediction'] = best_model.predict(scaler.transform(X))\n",
    "dataset_encoded['Exited Prediction Probability'] = best_model.predict_proba(scaler.transform(X))[:,1]\n",
    "\n",
    "# Export the data with predictions\n",
    "dataset_encoded.to_csv(\"bank_churn_data_with_predictions.csv\", index=False)\n",
    "print(\"Dataset with predictions saved as 'bank_churn_data_with_predictions.csv'\")\n",
    "\n",
    "# Create feature importance dataframe\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importance.to_csv(\"feature_importance.csv\", index=False)\n",
    "print(\"Feature importance saved as 'feature_importance.csv'\")\n",
    "\n",
    "# Save the best model\n",
    "with open('best_churn_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "print(\"Best model saved as 'best_churn_model.pkl'\")\n",
    "\n",
    "# Save the scaler\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "print(\"Scaler saved as 'scaler.pkl'\")\n",
    "\n",
    "print(\"\\nAll operations completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=== ANALYSIS SUMMARY ===\\n\")\n",
    "print(f\"Original dataset shape: {dataset_encoded.shape}\")\n",
    "print(f\"Selected features: {len(selected_vars)}\")\n",
    "print(f\"Best model: {type(best_model).__name__}\")\n",
    "print(f\"Best model accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Best model ROC AUC: {roc_auc_score(y_test, y_pred_rf):.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "print(feature_importance.head())\n",
    "\n",
    "print(\"\\nFiles generated:\")\n",
    "print(\"1. bank_churn_data_with_predictions.csv - Dataset with predictions\")\n",
    "print(\"2. feature_importance.csv - Feature importance rankings\")\n",
    "print(\"3. best_churn_model.pkl - Trained model for future predictions\")\n",
    "print(\"4. scaler.pkl - Scaler for preprocessing new data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}